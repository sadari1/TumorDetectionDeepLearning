{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Convolutional Network\n",
    "\n",
    "Rough implementation of the encoder-decoder temporal convolutional network found in this paper: https://arxiv.org/abs/1611.05267\n",
    "\n",
    "Model is not an exact replica of the one described in the paper, and a flattening layer was added before the output layer. Hyperparameters are also slightly different regarding the filter in each convolutional layer.\n",
    "\n",
    "Tested the model on sequential MNIST data, which refers to a flattened version of each MNIST image. \n",
    "\n",
    "Model obtained 98.82% training accuracy and 96.81% testing accuracy.\n",
    "\n",
    "Training time was nearly 34 minutes on an Nvidia GTX 1060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-51e287476e38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Model'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.layers import Convolution1D, Dense, MaxPool1D\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import keras\n",
    "from keras.layers import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (784, 1) \n",
      "X_train shape: (60000, 784, 1) \n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Reshaping it so that it is (60000, 784, 1) instead of (60000, 28, 28, 1) since it's not channels first\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows * img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows * img_cols)\n",
    "    input_shape = (1, img_rows * img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols, 1)\n",
    "input_shape = (img_rows * img_cols, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "print('Input shape: %s \\nX_train shape: %s \\nY_train shape: %s' % (input_shape, x_train.shape, y_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shumpu\\Anaconda2\\envs\\p36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bee72aa67485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mTCN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#This is the model itself, adapted from the paper and slightly modified.\n",
    "\n",
    "\n",
    "## ENCODER STAGE\n",
    "input_layer = Input(shape=(input_shape ))\n",
    "\n",
    "conv_encoder1 = keras.layers.convolutional.Conv1D(filters=int(input_shape[0]),\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(input_layer)\n",
    "pool_1 = keras.layers.convolutional.MaxPooling1D(pool_size=2, strides=2)(conv_encoder1)\n",
    "\n",
    "conv_encoder2 = keras.layers.convolutional.Conv1D(filters=int(input_shape[0]/2),\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(pool_1)\n",
    "\n",
    "pool_2 = keras.layers.convolutional.MaxPooling1D(pool_size=2, strides=2)(conv_encoder2)\n",
    "\n",
    "encoder = Dense(int(input_shape[0]/4), activation='relu')(pool_2)\n",
    "\n",
    "\n",
    "## DECODER STAGE\n",
    "upsample_1 = keras.layers.convolutional.UpSampling1D(size=2)(encoder)\n",
    "\n",
    "conv_decoder1 = keras.layers.convolutional.Conv1D(filters=int(input_shape[0]/2),\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(upsample_1)\n",
    "\n",
    "upsample_2 = keras.layers.convolutional.UpSampling1D(size=2)(conv_decoder1)\n",
    "\n",
    "conv_decoder2 = keras.layers.convolutional.Conv1D(filters=input_shape[0],\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(upsample_2)\n",
    "#Flattening layer to match y_test's shape\n",
    "flat = keras.layers.Flatten()(conv_decoder2)\n",
    "output_layer = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "TCN = Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCN.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"model_seqMnist.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 209s - loss: 0.2286 - acc: 0.9296 - val_loss: 0.1552 - val_acc: 0.9497\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 202s - loss: 0.1322 - acc: 0.9598 - val_loss: 0.1238 - val_acc: 0.9623\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 204s - loss: 0.1090 - acc: 0.9682 - val_loss: 0.1168 - val_acc: 0.9653\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0934 - acc: 0.9717 - val_loss: 0.1060 - val_acc: 0.9669\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0810 - acc: 0.9762 - val_loss: 0.1162 - val_acc: 0.9654\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0708 - acc: 0.9786 - val_loss: 0.1099 - val_acc: 0.9665\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 202s - loss: 0.0609 - acc: 0.9819 - val_loss: 0.1120 - val_acc: 0.9671\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0520 - acc: 0.9847 - val_loss: 0.1065 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0451 - acc: 0.9862 - val_loss: 0.1139 - val_acc: 0.9680\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0378 - acc: 0.9882 - val_loss: 0.1205 - val_acc: 0.9681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152e9b5f550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCN.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks = [checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.12048382413223153\n",
      "Test accuracy: 0.9681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = TCN.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
