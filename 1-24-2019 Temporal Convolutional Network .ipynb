{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Convolutional Network\n",
    "\n",
    "Rough implementation of the encoder-decoder temporal convolutional network found in this paper: https://arxiv.org/abs/1611.05267\n",
    "\n",
    "Model is not an exact replica of the one described in the paper, and a flattening layer was added before the output layer. Hyperparameters are also slightly different regarding the filter in each convolutional layer.\n",
    "\n",
    "Tested the model on sequential MNIST data, which refers to a flattened version of each MNIST image. \n",
    "\n",
    "Model obtained 98.82% training accuracy and 96.81% testing accuracy.\n",
    "\n",
    "Training time was nearly 34 minutes on an Nvidia GTX 1060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.layers import Convolution1D, Dense, MaxPool1D\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (784, 1) \n",
      "X_train shape: (60000, 784, 1) \n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Reshaping it so that it is (60000, 784, 1) instead of (60000, 28, 28, 1) since it's not channels first\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows * img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows * img_cols)\n",
    "    input_shape = (1, img_rows * img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols, 1)\n",
    "input_shape = (img_rows * img_cols, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "print('Input shape: %s \\nX_train shape: %s \\nY_train shape: %s' % (input_shape, x_train.shape, y_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This is the model itself, adapted from the paper and slightly modified.\n",
    "\n",
    "\n",
    "## ENCODER STAGE\n",
    "input_layer = Input(shape=(input_shape ))\n",
    "\n",
    "conv_encoder1 = keras.layers.convolutional.Conv1D(filters=int(input_shape[0]),\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(input_layer)\n",
    "pool_1 = keras.layers.convolutional.MaxPooling1D(pool_size=2, strides=2)(conv_encoder1)\n",
    "\n",
    "conv_encoder2 = keras.layers.convolutional.Conv1D(filters=int(input_shape[0]/2),\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(pool_1)\n",
    "\n",
    "pool_2 = keras.layers.convolutional.MaxPooling1D(pool_size=2, strides=2)(conv_encoder2)\n",
    "\n",
    "encoder = Dense(int(input_shape[0]/4), activation='relu')(pool_2)\n",
    "\n",
    "\n",
    "## DECODER STAGE\n",
    "upsample_1 = keras.layers.convolutional.UpSampling1D(size=2)(encoder)\n",
    "\n",
    "conv_decoder1 = keras.layers.convolutional.Conv1D(filters=int(input_shape[0]/2),\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(upsample_1)\n",
    "\n",
    "upsample_2 = keras.layers.convolutional.UpSampling1D(size=2)(conv_decoder1)\n",
    "\n",
    "conv_decoder2 = keras.layers.convolutional.Conv1D(filters=input_shape[0],\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(upsample_2)\n",
    "#Flattening layer to match y_test's shape\n",
    "flat = keras.layers.Flatten()(conv_decoder2)\n",
    "output_layer = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "TCN = Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCN.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"model_seqMnist.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 784, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 784, 784)          2352      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 392, 784)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 392, 392)          615048    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 196, 392)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 196, 196)          77028     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1 (None, 392, 196)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 392, 392)          154056    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_6 (UpSampling1 (None, 784, 392)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 784, 784)          615440    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 614656)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                6146570   \n",
      "=================================================================\n",
      "Total params: 7,610,494\n",
      "Trainable params: 7,610,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TCN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 209s - loss: 0.2286 - acc: 0.9296 - val_loss: 0.1552 - val_acc: 0.9497\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 202s - loss: 0.1322 - acc: 0.9598 - val_loss: 0.1238 - val_acc: 0.9623\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 204s - loss: 0.1090 - acc: 0.9682 - val_loss: 0.1168 - val_acc: 0.9653\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0934 - acc: 0.9717 - val_loss: 0.1060 - val_acc: 0.9669\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0810 - acc: 0.9762 - val_loss: 0.1162 - val_acc: 0.9654\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0708 - acc: 0.9786 - val_loss: 0.1099 - val_acc: 0.9665\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 202s - loss: 0.0609 - acc: 0.9819 - val_loss: 0.1120 - val_acc: 0.9671\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0520 - acc: 0.9847 - val_loss: 0.1065 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0451 - acc: 0.9862 - val_loss: 0.1139 - val_acc: 0.9680\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 203s - loss: 0.0378 - acc: 0.9882 - val_loss: 0.1205 - val_acc: 0.9681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152e9b5f550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCN.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks = [checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.12048382413223153\n",
      "Test accuracy: 0.9681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = TCN.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
