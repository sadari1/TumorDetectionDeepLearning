{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilated Temporal Convolutional Network\n",
    "\n",
    "Implementation of a dilated TCN loosely based on the dilated temporal convolutional network found in this paper: https://arxiv.org/abs/1611.05267\n",
    "\n",
    "Model is not an exact replica of the one described in the paper, and a flattening layer was added before the output layer. Hyperparameters are also slightly different regarding the filter in each convolutional layer, and the last two layers feeding into the output layer are temporal convolutional layers without dilations.\n",
    "\n",
    "This architecture took significantly less time to train than the encoder-decoder network, while obtaining a high training and testing accura\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Tested the model on sequential MNIST data, which refers to a flattened version of each MNIST image. \n",
    "\n",
    "Model obtained a 99.68% training accuracy and 97.02% testing accuracy.\n",
    "\n",
    "Training time was around 10 and a half minutes on an Nvidia GTX 1060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.layers import Convolution1D, Dense, MaxPool1D\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (784, 1) \n",
      "X_train shape: (60000, 784, 1) \n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 15\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Reshaping it so that it is (60000, 784, 1) instead of (60000, 28, 28, 1) since it's not channels first\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows * img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows * img_cols)\n",
    "    input_shape = (1, img_rows * img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols, 1)\n",
    "input_shape = (img_rows * img_cols, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "print('Input shape: %s \\nX_train shape: %s \\nY_train shape: %s' % (input_shape, x_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_layer = Input(shape=(input_shape ))\n",
    "\n",
    "#Series of temporal convolutional layers with dilations increasing by powers of 2.\n",
    "conv_1 = keras.layers.convolutional.Conv1D(filters=128,\n",
    "                                                   kernel_size=2,\n",
    "                                                   dilation_rate=1,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(input_layer)\n",
    "\n",
    "conv_2 = keras.layers.convolutional.Conv1D(filters=128,\n",
    "                                                   kernel_size=2,\n",
    "                                                   dilation_rate=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(conv_1)\n",
    "\n",
    "conv_3 = keras.layers.convolutional.Conv1D(filters=128,\n",
    "                                                   kernel_size=2,\n",
    "                                                   dilation_rate=4,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(conv_2)\n",
    "\n",
    "conv_4 = keras.layers.convolutional.Conv1D(filters=128,\n",
    "                                                   kernel_size=2,\n",
    "                                                   dilation_rate=8,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(conv_3)\n",
    "\n",
    "#Two relu convolutional layers without dilations to feed into the output layer\n",
    "conv_5 = keras.layers.convolutional.Conv1D(filters=128,\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(conv_4)\n",
    "\n",
    "conv_6 = keras.layers.convolutional.Conv1D(filters=128,\n",
    "                                                   kernel_size=2,\n",
    "                                                   padding='causal',\n",
    "                                                   strides=1,\n",
    "                                                   input_shape=input_shape,\n",
    "                                                   activation = 'relu')(conv_5)\n",
    "#Flatten to match dimensions of our y_test\n",
    "flat = keras.layers.Flatten()(conv_5)\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax')(flat)\n",
    "\n",
    "TCN = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 784, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 784, 128)          384       \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 784, 128)          32896     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 784, 128)          32896     \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 784, 128)          32896     \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 784, 128)          32896     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1003530   \n",
      "=================================================================\n",
      "Total params: 1,135,498\n",
      "Trainable params: 1,135,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TCN.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"model_seqMnistDilated.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "\n",
    "TCN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 44s - loss: 0.2028 - acc: 0.9385 - val_loss: 0.1034 - val_acc: 0.9677\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0994 - acc: 0.9696 - val_loss: 0.0970 - val_acc: 0.9714\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0733 - acc: 0.9773 - val_loss: 0.0941 - val_acc: 0.9711\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0544 - acc: 0.9827 - val_loss: 0.1052 - val_acc: 0.9694\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0362 - acc: 0.9887 - val_loss: 0.1056 - val_acc: 0.9728\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0252 - acc: 0.9915 - val_loss: 0.1354 - val_acc: 0.9648\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 43s - loss: 0.0199 - acc: 0.9930 - val_loss: 0.1267 - val_acc: 0.9705\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0141 - acc: 0.9953 - val_loss: 0.1503 - val_acc: 0.9664\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0128 - acc: 0.9957 - val_loss: 0.1369 - val_acc: 0.9711\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0103 - acc: 0.9965 - val_loss: 0.1599 - val_acc: 0.9669\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0081 - acc: 0.9972 - val_loss: 0.1843 - val_acc: 0.9672\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0108 - acc: 0.9962 - val_loss: 0.1718 - val_acc: 0.9660\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0082 - acc: 0.9973 - val_loss: 0.2010 - val_acc: 0.9630\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0062 - acc: 0.9981 - val_loss: 0.1858 - val_acc: 0.9656\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 42s - loss: 0.0090 - acc: 0.9968 - val_loss: 0.1748 - val_acc: 0.9702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x239b1a69780>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCN.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks = [checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.17482566874956265\n",
      "Test accuracy: 0.9702\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = TCN.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
